---
layout : post
title : "1주차"
---

# 3장 분류

## 3.1 MNIST

MNIST데이터셋: 손으로 쓴 70,000개의 작은 숫자 이미지 데이터셋

DESCR: 데이터셋 설명

data: 입력 데이터, 일반적으로 2D 넘파이 배열

target: 레이블, 일반적으로 1D 넘파이 배열
```python
import sys

assert sys.version_info >= (3, 7)
```
```python
import matplotlib.pyplot as plt

plt.rc('font', size=14)
plt.rc('axes', labelsize=14, titlesize=14)
plt.rc('legend', fontsize=14)
plt.rc('xtick', labelsize=10)
plt.rc('ytick', labelsize=10)
```
```python
from pathlib import Path

IMAGES_PATH = Path() / "images" / "classification"
IMAGES_PATH.mkdir(parents=True, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = IMAGES_PATH / f"{fig_id}.{fig_extension}"
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)
```
```python
import tensorflow as tf
import numpy as np


(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_all = (np.concatenate([x_train, x_test], axis=0))
y = np.concatenate([y_train, y_test], axis=0)

X = x_all.reshape(x_all.shape[0], -1)

print("전체 데이터 (2D 변환) 크기:", X.shape)
print("전체 라벨 크기: ", y.shape)
```
```python
X
X.shape
y
y.shape
```
```python
import matplotlib.pyplot as plt

def plot_digit(image_data):
    image = image_data.reshape(28, 28)
    plt.imshow(image, cmap="binary")
    plt.axis("off")

some_digit = X[0]
plot_digit(some_digit)
plt.show()
```
```python
y[0]
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```

## 3.2 이진 분류기 훈련

이진 분류기: 두 개의 클래스를 구분

확률적 경사 하강법(SGD) 분류기
```python
y_train_5 = (y_train == 5)  # 5는 True고, 다른 숫자는 모두 False
y_test_5 = (y_test == 5)
```
```python
from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train_5)
```
```python
sgd_clf.predict([some_digit])
```

## 3.3 성능 측정

### 3.3.1 교차 검증을 사용한 정확도 측정

k-폴드 교차 검증: '정확도'를 불균형한 데이터셋을 다룰 때 성능 측정 지표로 선호 x 
```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone

skfolds = StratifiedKFold(n_splits=3)  # 데이터셋이 미리 섞여 있지 않다면
                                       # shuffle=True를 추가하세요.
for train_index, test_index in skfolds.split(X_train, y_train_5):
    clone_clf = clone(sgd_clf)
    X_train_folds = X_train[train_index]
    y_train_folds = y_train_5[train_index]
    X_test_fold = X_train[test_index]
    y_test_fold = y_train_5[test_index]

    clone_clf.fit(X_train_folds, y_train_folds)
    y_pred = clone_clf.predict(X_test_fold)
    n_correct = sum(y_pred == y_test_fold)
    print(n_correct / len(y_pred))
```
```python
from sklearn.model_selection import cross_val_score

cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```
```python
from sklearn.dummy import DummyClassifier

dummy_clf = DummyClassifier()
dummy_clf.fit(X_train, y_train_5)
print(any(dummy_clf.predict(X_train)))
```
```python
cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```
### 3.3.2 오차 행렬

행: 실제 클래스

열: 예측한 클래스

1종 오류: False Positive, 맞다고 예측했지만 실제로 아님.

2종 오류: False Negative, 아니라고 예측했지만 실제로 맞음.
```python
from sklearn.model_selection import cross_val_predict

y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
```
```python
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_train_5, y_train_pred)
cm
```
```python
y_train_perfect_predictions = y_train_5  # 완벽한 분류기일 경우
confusion_matrix(y_train_5, y_train_perfect_predictions)
```
###3.3.3 정밀도와 재현율

정밀도: TP / (TP+FP), 예측한 양성들 중 실제 양성의 비율

재현율(민감도, TPR): TP / (TP+FN), 실제 양성들 중 양성으로 예측된 비율

F1점수: 2 / (1/정밀도+1/재현율)

```python
from sklearn.metrics import precision_score, recall_score

precision_score(y_train_5, y_train_pred)  # == 3530 / (687 + 3530)
recall_score(y_train_5, y_train_pred)  # == 3530 / (1891 + 3530)
```
```python
from sklearn.metrics import f1_score

f1_score(y_train_5, y_train_pred)
```
### 3.3.4 정밀도/재현율 트레이드오프

정밀도와 재현율이 반비례

결정 함수: 결정 임곗값을 기준으로 예측을 양성/음성 가름.

 임곗값보다 크면 양성, 임곗값보다 작으면 음성
 
 보통 임곗값이 높을수록 재현율은 낮아지고, 정밀도는 높아짐.

정밀도/재현율(PR) 곡선: 하강점 직전을 정밀도/재현율 트레이드오프로 선택하는 것이 적절
```python
y_scores = sgd_clf.decision_function([some_digit])
y_scores
threshold = 0
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
```
```python
threshold = 3000
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
```
```python
y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,
                             method="decision_function")
```
```python
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)
```
```python
plt.plot(thresholds, precisions[:-1], "b--", label="정밀도", linewidth=2)
plt.plot(thresholds, recalls[:-1], "g-", label="재현율", linewidth=2)
plt.vlines(threshold, 0, 1.0, "k", "dotted", label="임곗값")
plt.show()

plt.plot(recalls, precisions, linewidth=2, label='정밀도/재현율 곡선')
plt.show()
```
```python
idx_for_90_precision = (precisions >= 0.90).argmax()
threshold_for_90_precision = thresholds[idx_for_90_precision]
threshold_for_90_precision
y_train_pred_90 = (y_scores >= threshold_for_90_precision)
precision_score(y_train_5, y_train_pred_90)
recall_at_90_precision = recall_score(y_train_5, y_train_pred_90)
recall_at_90_precision
```
### 3.3.5 ROC 곡선

수신기 조작 특성(ROC) 곡선: FPR(폴-아웃)에 대한 TPR 곡선

FPR = 1 - TNR(특이도)

곡선 아래의 면적(AUC): 완벽한 ROC는 AUC가 1, 완전한 랜덤 분류기는 0.5
```python
from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)
```
```python
idx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()
tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]

plt.figure(figsize=(6, 5))  # 추가 코드
plt.plot(fpr, tpr, linewidth=2, label="ROC 곡선")
plt.plot([0, 1], [0, 1], 'k:', label="랜덤 분류기의 ROC 곡선")
plt.plot([fpr_90], [tpr_90], "ko", label="90%정밀도에 대한 임곗값")
plt.show()
```
```python
from sklearn.metrics import roc_auc_score

roc_auc_score(y_train_5, y_scores)

from sklearn.ensemble import RandomForestClassifier

forest_clf = RandomForestClassifier(random_state=42)

y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,
                                    method="predict_proba")

y_probas_forest[:2]
```
```python
y_scores_forest = y_probas_forest[:, 1]
precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve(
    y_train_5, y_scores_forest)
```
```python
plt.plot(recalls_forest, precisions_forest, "b-", linewidth=2,
         label="랜덤 포레스트")
plt.plot(recalls, precisions, "--", linewidth=2, label="SGD")
plt.show()
```
```python
y_train_pred_forest = y_probas_forest[:, 1] >= 0.5  # 양성 확률 ≥ 50%
f1_score(y_train_5, y_train_pred_forest)
roc_auc_score(y_train_5, y_scores_forest)
```

## 3.4 다중 분류

다중 분류기: 둘 이상의 클래스 구별

알고리즘에 따라 여러 클래스 직접 처리가능한 것이 있고, 이진 분류만 가능한 것이 있음

-> OvR, OvA: 이진 분류기 여러 개를 훈련시키고, 분류 시 각 분류기의 결정 점수 중에서 가장 높은 것을 클래스로 선택

-> OvO: 각 조합마다 이진 분류기 훈련, 각 분류기의 훈련에 전체 훈련 세트 중 구별할 두 클래스에 해당하는 샘플만 있으면 되는 것이 장점
```python
from sklearn.svm import SVC

svm_clf = SVC(random_state=42)
svm_clf.fit(X_train[:2000], y_train[:2000])  # y_train_5가 아니고 y_train을 사용합니다.
svm_clf.predict([some_digit])

some_digit_scores = svm_clf.decision_function([some_digit])
some_digit_scores.round(2)

class_id = some_digit_scores.argmax()
class_id

svm_clf.classes_
svm_clf.classes_[class_id]
```
```python
from sklearn.multiclass import OneVsRestClassifier

ovr_clf = OneVsRestClassifier(SVC(random_state=42))
ovr_clf.fit(X_train[:2000], y_train[:2000])

ovr_clf.predict([some_digit])

len(ovr_clf.estimators_)

sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train)
sgd_clf.predict([some_digit])

sgd_clf.decision_function([some_digit]).round()

cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring="accuracy")
```
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype("float64"))
cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring="accuracy")
```

## 3.5 오류 분석

오차 행렬을 컬러 그래프로 나타내면 분석 용이

대부분의 이미지가 주대각선에 있으면 이미지가 올바르게 분류된 것

오류를 더 눈에 띄게 만들려면 올바른 예측에 대한 가중치를 0으로 설정.

선형 분류기: 클래스마다 픽셀에 가중치를 할당하고 새로운 이미지에 대해 단순히 픽셀 강도의 가중치 합을 클래스의 점수로 계산

데이터 증식: 훈련 이미지를 약간 이동시키거나 회전된 변형 이미지로 훈련 집합을 보강
```python
from sklearn.metrics import ConfusionMatrixDisplay

y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)
plt.show()

ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,
                                        normalize="true", values_format=".0%")
plt.show()

sample_weight = (y_train_pred != y_train)
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,
                                        sample_weight=sample_weight,
                                        normalize="true", values_format=".0%")
plt.show()
```
```python
cl_a, cl_b = '3', '5'
X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]
X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]
X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]
X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]
```

## 3.6 다중 레이블 분류

다중 레이블 분류 시스템: 여러 개의 이진 꼬리표를 출력하는 분류 시스템

평가1: 각 레이블의 F1 점수를 구하고 평균 점수를 계산, 레이블에 클래스의 지지도(타깃 레이블에 속한 샘플 수)를 가중치로 두는 것

평가2: 레이블당 하나의 모델을 학습(레이블 간의 의존성 포착의 어려움) -> 모델을 체인으로 구성, 한 모델이 예측 시 입력 특성과 체인 앞에 있는 모델의 모든 예측 사용
```python
import numpy as np
from sklearn.neighbors import KNeighborsClassifier

y_train_large = (y_train >= '7')
y_train_odd = (y_train.astype('int8') % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]

knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)

knn_clf.predict([some_digit])

y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)
f1_score(y_multilabel, y_train_knn_pred, average="macro")
```
```python
from sklearn.multioutput import ClassifierChain

chain_clf = ClassifierChain(SVC(), cv=3, random_state=42)
chain_clf.fit(X_train[:2000], y_multilabel[:2000])

chain_clf.predict([some_digit])
```

## 3.7 다중 출력 분류

다중 출력 다중 클래스 분류: 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화

ex)잡음 제거: 잡음 많은 숫자 이미지 -> 깨끗한 숫자 이미지
```python
np.random.seed(42)  # 동일하게 재현되게 하려고 지정합니다
noise = np.random.randint(0, 100, (len(X_train), 784))
X_train_mod = X_train + noise
noise = np.random.randint(0, 100, (len(X_test), 784))
X_test_mod = X_test + noise
y_train_mod = X_train
y_test_mod = X_test
```
